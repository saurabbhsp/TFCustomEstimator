{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(object):\n",
    "\n",
    "    def __init__(self, model_id):\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def get_input(self, mode):\n",
    "        \"\"\"Implement in derived class\"\"\"\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def get_train_inputs(self):\n",
    "        return self.get_input(tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    def get_predict_inputs(self):\n",
    "        return self.get_input(tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "    def base_model(self, features, mode):\n",
    "        \"\"\"Implemented in the derived class\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def get_train_op(self, loss, step):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def get_loss(self, predictions, labels):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def build_estimator(self, features, labels, mode, config=None):\n",
    "        \"\"\"This method will build the estimator\"\"\"\n",
    "        predictions = self.base_model(features, mode)\n",
    "        network_arguments = dict(mode=mode, predictions=predictions)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            \"\"\"Execution pipeline\"\"\"\n",
    "            return tf.estimator.EstimatorSpec(**network_arguments)\n",
    "\n",
    "        \n",
    "        loss = self.get_loss(predictions, labels)\n",
    "        network_arguments['loss'] = loss\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(**network_arguments)\n",
    "\n",
    "        \"\"\"Will provide current step. In this case the epoch\"\"\"\n",
    "        step = tf.train.get_or_create_global_step()\n",
    "        \"\"\"Collection of operations. These are the operations\n",
    "        that are to be executed after training step\"\"\"\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = self.get_train_op(loss = loss,\n",
    "                                         step = step)\n",
    "\n",
    "        network_arguments['train_op'] = train_op\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            return tf.estimator.EstimatorSpec(**network_arguments)\n",
    "\n",
    "    def get_estimator(self, config=None):\n",
    "        \"\"\"Get the `tf.estimator.Estimator` defined by this builder.\"\"\"\n",
    "        return tf.estimator.Estimator(\n",
    "            self.build_estimator, self.model_dir, config=config)\n",
    "\n",
    "    def train(self, config=None, **train_kwargs):\n",
    "        \"\"\"Wrapper around `tf.estimator.Estimator.train`.\"\"\"\n",
    "        estimator = self.get_estimator(config=config)\n",
    "        estimator.train(self.get_train_inputs, **train_kwargs)\n",
    "\n",
    "    def evaluate(self, config=None, **train_kwargs):\n",
    "        \"\"\"Wrapper around `tf.estimator.Estimator.train`.\"\"\"\n",
    "        estimator = self.get_estimator(config=config)\n",
    "        estimator.evaluate(self.get_predict_inputs, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def initialize_datasets():\n",
    "    data = fetch_olivetti_faces()\n",
    "    targets = data.target\n",
    "    features = data.images\n",
    "    encoder = OneHotEncoder()\n",
    "    targets = encoder.fit_transform(targets.reshape(-1, 1)).todense()\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(features, targets, test_size=0.1)\n",
    "\n",
    "    return {'train':{'features': xTrain, 'labels' : yTrain}, 'test':{'features': xTest, 'labels' : yTest}}\n",
    "\n",
    "class Classifier(ModelBuilder):\n",
    "    \n",
    "    \n",
    "    def __init__(self, model_id):\n",
    "        super(Classifier, self).__init__(model_id)\n",
    "        self.data_dictionary = initialize_datasets()\n",
    "    \n",
    "    def make_dataset(self, features, labels):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "        return dataset\n",
    "    \n",
    "    def get_input(self, mode):\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = self.make_dataset(self.data_dictionary['train']['features'].reshape(360, -1),\n",
    "                                   self.data_dictionary['train']['labels'].reshape(360, -1))\n",
    "        else:\n",
    "            dataset = self.make_dataset(self.data_dictionary['test']['features'],\n",
    "                                   self.data_dictionary['test']['labels'])\n",
    "        \n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.prefetch(2)\n",
    "\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    def base_model(self, features, mode):\n",
    "        features = tf.reshape(features, [1, 64 * 64])\n",
    "        predictions = tf.nn.softmax(tf.matmul(features, tf.Variable(tf.zeros([64 * 64, 40]))) + tf.Variable(tf.zeros([40])))\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_loss(self, predictions, labels):\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "        loss_function = tf.reduce_mean(-tf.reduce_sum(labels * tf.log(predictions), reduction_indices=1))\n",
    "        return loss_function\n",
    "    \n",
    "    def get_train_op(self, loss, step):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_operation = optimizer.minimize(loss, step)\n",
    "        return train_operation\n",
    "    \n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return os.path.join(os.getcwd(), \"model\", self.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/saurabh/Documents/tfMulti/model/12', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd7b4f0dac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/saurabh/Documents/tfMulti/model/12/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.6888795, step = 1\n",
      "INFO:tensorflow:global_step/sec: 759.56\n",
      "INFO:tensorflow:loss = 1.3600674, step = 101 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 1420.25\n",
      "INFO:tensorflow:loss = 13.213498, step = 201 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1235.65\n",
      "INFO:tensorflow:loss = 0.42529956, step = 301 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1426.64\n",
      "INFO:tensorflow:loss = 7.0349064, step = 401 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1449.23\n",
      "INFO:tensorflow:loss = 13.983682, step = 501 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1335.76\n",
      "INFO:tensorflow:loss = 1.7622852, step = 601 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1293.38\n",
      "INFO:tensorflow:loss = 0.13245636, step = 701 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1389.13\n",
      "INFO:tensorflow:loss = 2.3623645, step = 801 (0.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 1344.8\n",
      "INFO:tensorflow:loss = 2.7287505, step = 901 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1287.5\n",
      "INFO:tensorflow:loss = 0.024340257, step = 1001 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1314.88\n",
      "INFO:tensorflow:loss = 2.742156, step = 1101 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1307.61\n",
      "INFO:tensorflow:loss = 0.75737154, step = 1201 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1302.91\n",
      "INFO:tensorflow:loss = 0.71259284, step = 1301 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1353.03\n",
      "INFO:tensorflow:loss = 7.784887, step = 1401 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1154.82\n",
      "INFO:tensorflow:loss = 0.19208294, step = 1501 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 860.418\n",
      "INFO:tensorflow:loss = 4.027994, step = 1601 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1242.11\n",
      "INFO:tensorflow:loss = 0.0016080546, step = 1701 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1368.26\n",
      "INFO:tensorflow:loss = 2.464985, step = 1801 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1210.86\n",
      "INFO:tensorflow:loss = 0.025198398, step = 1901 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1367.94\n",
      "INFO:tensorflow:loss = 10.467796, step = 2001 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1285.2\n",
      "INFO:tensorflow:loss = 0.2269905, step = 2101 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1300.41\n",
      "INFO:tensorflow:loss = 0.6110501, step = 2201 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1430.88\n",
      "INFO:tensorflow:loss = 0.118893005, step = 2301 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1426.52\n",
      "INFO:tensorflow:loss = 0.020308096, step = 2401 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1429.15\n",
      "INFO:tensorflow:loss = 0.008604124, step = 2501 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1425.47\n",
      "INFO:tensorflow:loss = 0.0036843854, step = 2601 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1296.32\n",
      "INFO:tensorflow:loss = 0.01673643, step = 2701 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1218.96\n",
      "INFO:tensorflow:loss = 0.010659984, step = 2801 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1370.2\n",
      "INFO:tensorflow:loss = 2.5507512, step = 2901 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1260.25\n",
      "INFO:tensorflow:loss = 3.5763427e-05, step = 3001 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 801.578\n",
      "INFO:tensorflow:loss = 0.010070677, step = 3101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 870.715\n",
      "INFO:tensorflow:loss = 0.033313088, step = 3201 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 1351.44\n",
      "INFO:tensorflow:loss = 2.002736e-05, step = 3301 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.789\n",
      "INFO:tensorflow:loss = 0.14813997, step = 3401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.204\n",
      "INFO:tensorflow:loss = 0.00020559755, step = 3501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 872.252\n",
      "INFO:tensorflow:loss = 0.00050724496, step = 3601 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.829\n",
      "INFO:tensorflow:loss = 0.00011552047, step = 3701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1007.79\n",
      "INFO:tensorflow:loss = 7.221521, step = 3801 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1002.54\n",
      "INFO:tensorflow:loss = -0.0, step = 3901 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1366.1\n",
      "INFO:tensorflow:loss = 0.004304182, step = 4001 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1427.65\n",
      "INFO:tensorflow:loss = 6.2741036, step = 4101 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1283.63\n",
      "INFO:tensorflow:loss = 2.9802368e-06, step = 4201 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1440.88\n",
      "INFO:tensorflow:loss = 0.23484312, step = 4301 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1420.19\n",
      "INFO:tensorflow:loss = 8.5119056e-05, step = 4401 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1377.23\n",
      "INFO:tensorflow:loss = 1.7720717, step = 4501 (0.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 1450.02\n",
      "INFO:tensorflow:loss = 0.0018165507, step = 4601 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1286.4\n",
      "INFO:tensorflow:loss = 0.023506405, step = 4701 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1257.55\n",
      "INFO:tensorflow:loss = 0.00014008072, step = 4801 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1388.09\n",
      "INFO:tensorflow:loss = 0.35920984, step = 4901 (0.072 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /home/saurabh/Documents/tfMulti/model/12/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0066867014.\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier(\"12\")\n",
    "classifier.train(max_steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
